[
["index.html", "STAT 454 Bayesian Statistics - Pet Adoption Chapter 1 Preface", " STAT 454 Bayesian Statistics - Pet Adoption Connie Zhang, Spring 2020 Macalester College Chapter 1 Preface Hello! Welcome to the bookdown of my STAT 454 Bayesian Statistics project! Have you ever wondered why some animals take a long time to get adopted while some take less time? I will try to answer this question in my project, flip to read my motivations! "],
["motivation.html", "Chapter 2 Motivation", " Chapter 2 Motivation I love animals! I have a dog and a cat (pictures below), and they mean the world to me. After becoming their “big sister”, I have been paying more attention to animal welfare in our society. I think it would be interesting to employ Bayesian statistical tools to analyze pet adoption speeds. There are not a lot of academic literature regarding pet adoption, but I’m sure we have all seen some news about crowded animal shelters and the saddening numbers of animals that get put down each year. I hope my project results can shine some lights on this issue. Here’s a website for some animal shelter statistics: https://petpedia.co/animal-shelter-statistics/ "],
["data-exploration.html", "Chapter 3 Data Exploration 3.1 Data Source 3.2 Variable Table 3.3 Visualizations", " Chapter 3 Data Exploration In this chapter, I will explain my data source, demonstrate visualizations and data cleaning strategy that helped inform my modelling process. 3.1 Data Source I found this data on kaggle, it is provided by PetFinder.com, the largest online platform for animal adoption in Malaysia. This data is collected by PetFinder.com since 2008 to 2019 regarding the information about cats and dogs and their adoption speed. Link to this data: https://www.kaggle.com/c/petfinder-adoption-prediction/data 3.2 Variable Table Below is a table for all the variables I will be exploring in this chapter. Variable Key Type 0 dog; 1 cat Health 0 healthy; 1 minor injury; 2 severe injury Sterilized 0 not sterilized; 1 sterilized Vaccinated 0 not vaccinated; 1 vaccinated Dewormed 0 not dewormed; 1 dewormed Age Group 0: 0-3 months; 1: 4-11 months; 2: 12-30 months; 3: 31-59 months; 4: 60-82 months; 5: 83 months or older Mixed Breed 0 not mixed breed; 1 mixed breed 3.3 Visualizations Now for some visualizations! 3.3.1 General Impressions From the bar graph, we can see that it’s very rare for animals to get adopted on the day of listing. First, let’s look at pet adoption speed in general. We can see very little animals are adopted on the day that they arrived at the shelter, roughly 1/5 of the animals are adopted in less than a week, 1/5 of the animals are adopted between 2-3 months. 1/4 of the animals are adopted between 8-30 days, and slightly more than 1/4 of the animals are adopted after 100 days of being listed. What is causing the difference between adoption speeds? adoption %&gt;% ggplot(aes(x=AdoptionSpeed))+ geom_bar() 3.3.2 Type Let’s look at how adoption speeds can differ by animal types. For this variable, I cleaned it so 0 would indiate dog, and 1 to indicate cat. We can see that there are more dogs than cats, and cats get adopted faster than dogs. This might be due to the fact that many Malaysians are Muslim and it is against their religion to come in contact with dogs. Furthermore, dogs in general require a lot more effort and care than cats, making adopting dogs a bigger commitment. adoption %&gt;% ggplot(aes(x=Type,fill=AdoptionSpeed))+geom_bar() This makes me wonder if people evaluate cats and dogs differently. Let’s check out two more visualizations of how age and size can impact dog and cat adoption separately. Our visualizations below doesn’t seem to show a big difference between people’s adoption criteria for cats and dogs. Therefore, we will be using “Type” as sa variable in this model. p1&lt;-adoption %&gt;% filter(Type==0) %&gt;% ggplot(aes(x=AgeGroup,fill=AdoptionSpeed))+geom_bar()+ggtitle(&quot;Dog&quot;) p2&lt;-adoption %&gt;% filter(Type==1) %&gt;% ggplot(aes(x=AgeGroup,fill=AdoptionSpeed))+geom_bar()+ggtitle(&quot;Cat&quot;) p3&lt;-adoption %&gt;% filter(Type==0) %&gt;% ggplot(aes(x=MaturitySize,fill=AdoptionSpeed))+geom_bar()+ggtitle(&quot;Dog&quot;) p4&lt;-adoption %&gt;% filter(Type==1) %&gt;% ggplot(aes(x=MaturitySize,fill=AdoptionSpeed))+geom_bar()+ggtitle(&quot;Cat&quot;) (p1|p2)/(p3|p4) 3.3.3 Health-related variables Now, when we adopt an animal, what are some base criterias? For me, it would be the health of an animal. Many people lead busy lives, they might not have time to care for a pet that needs medical attention. The visualization below shows 4 graphs of how an animal’s general health, sterilization, dewormed, and vaccination status can affect adoption speed. In these graphs 0 means no health issues, sterilization, deworming, and vaccination. 1 means minor health issue, sterilized, dewormed, and vaccinated. 2 means severe health issues. We would generally expect that if the factor that gives the animal better health outcome (such as being vaccinated), then the animal would be more likely to get adopted faster. However, this doesn’t seem to be the case for these factors except for health. It seems like if an animal is not sterilized, dewormed, or vaccinated, they are actually more likely to get adopted faster. Nevertheless, these factors seem to impact adoption speeds. We would also be doing more digging in the next section. p5&lt;-adoption %&gt;% ggplot(aes(x=Health, fill=AdoptionSpeed))+ geom_bar(position=&quot;fill&quot;) p6&lt;-adoption %&gt;% na.omit() %&gt;% ggplot(aes(x=Sterilized,fill=AdoptionSpeed))+ geom_bar(position=&quot;fill&quot;) p7&lt;-adoption %&gt;% na.omit() %&gt;% ggplot(aes(x=Dewormed,fill=AdoptionSpeed))+ geom_bar(position=&quot;fill&quot;) p8&lt;-adoption %&gt;% na.omit() %&gt;% ggplot(aes(x=Vaccinated,fill=AdoptionSpeed))+ geom_bar(position=&quot;fill&quot;) (p5|p6)/(p7|p8) 3.3.4 Age and Age Group Another informative variable will be Age. Many people would be more inclined to adopt puppies and kittens. Let’s look at the general age distribution. We see that most of the animals are younger than 1 year old, and there are small spikes at 24 and 36. This is probably because it is hard to determine the animal’s age by month, so many people probably just report the approximate age of the animal in year. Moreover, a 2-year-old animal probably won’t be a lot more likely to get adopted faster than a 3-year-old animal. Therefore, putting the age into groups would probably be a better approach. I grouped the age by similar distribution of adoption speed. Age groups 0-5 correspond to animals aged 0-3,4-11,12-30,31-59,60-82,and 82 and older months, respectively. We could see that young animals are more likely to get adopted faster. p9&lt;-adoption %&gt;% ggplot(aes(x=Age))+geom_histogram()+xlim(-1,37) p10&lt;-adoption %&gt;% ggplot(aes(x=AgeGroup,fill=AdoptionSpeed))+geom_bar() p9|p10 Now, let’s dig deeper into the relationship between Age and health outcomes. We can see that younger animals (particularly those in age group 0 and 1) are less likely to get sterilized. This is probably because the animals are too young for the procedure to be done before they were adopted. adoption %&gt;% na.omit() %&gt;% ggplot(aes(x=AgeGroup,fill=Sterilized))+ geom_bar(position=&quot;fill&quot;) 3.3.5 The mysterious Breed 307 When I’m exploring breed, breed 307 seems to make up about 1/3 of the data. We can also see that breed 307 is more likely to get adopted slower than other breeds. It turns out this is mixed breed! This makes sense since people might not consider mixed breed animals as attractive. adoption %&gt;% ggplot(aes(x=MixedBreed,fill=AdoptionSpeed))+ geom_bar(position=&quot;fill&quot;) 3.3.6 Other factors There are some other factors that I thought would be significant but turns out to be false. For example, magnitude and score. “magnitude” and “score” are the two variables related to description sentiments. These are generated by Google’s Natural Language API. I extracted these variables from the json files and added them to my data. “Score” refers to how negative and positive the description is, -1 being the most negative, 1 being the most positive. “Magnitude” indicates the strength of the description. Almost all descriptions have a positive score since this is a pet adoption website, and the magnitude of the descriptions seem to be pretty similar from each other. p10&lt;-adoption %&gt;% ggplot(aes(x=score))+geom_histogram() p11&lt;-adoption %&gt;% ggplot(aes(x=magnitude))+geom_histogram() p10|p11 I also thought that the main color of the animals could be informative. However, the visualization does not show any apparent difference between color and adoption speed. adoption %&gt;% ggplot(aes(x=Color1, fill=AdoptionSpeed))+geom_bar(position=&quot;fill&quot;) "],
["modelling.html", "Chapter 4 Modelling 4.1 Set Up 4.2 Model 1 4.3 Model 2 4.4 Making some adjustments 4.5 Model 3", " Chapter 4 Modelling Have you ever wondered what to do when you want to predict more than 2 categories, and these categories seem to be ordered? Ordinal logistic regression is the way to go! In the case of pet adoption speeds, we have 5 categories, with group 0 being the fastest adoption speed, 5 being the slowest. For ordered logistic regression, we assume that the relationship between each pair of outcome groups is the same. This is called the proportional odds assumption. In other words, the coefficient for variable A will be the same regardless of whether it’s describing the relationship between outcome group 1 and 2, or outcome group 2 and 3. 4.1 Set Up First, let’s load some essential package. We will also create a sample of 1000 for faster modelling. load(&quot;adoption.RData&quot;) set.seed(454) mysample &lt;- adoption[sample(1:nrow(adoption), 1000, replace=FALSE),] Below is the function I wrote to compute the accuracy of each model. ordinal_accuracy&lt;-function(post_preds,mydata){ post_preds&lt;-as.data.frame(post_preds) results&lt;-c() for (j in (1:length(post_preds))){ results[j]&lt;-as.numeric(tail(names(sort(table(post_preds[,j]))))[5]) } results&lt;-as.data.frame(results) compare&lt;-cbind(results,mydata$AdoptionSpeed) compare&lt;-compare %&gt;%mutate(results=as.numeric(results)) compare&lt;-compare %&gt;% mutate(`mydata$AdoptionSpeed`=as.numeric(`mydata$AdoptionSpeed`)) compare&lt;-compare %&gt;%mutate(accuracy=ifelse(as.numeric(results)==as.numeric(`mydata$AdoptionSpeed`),1,0)) print(sum(compare$accuracy)/length(post_preds)) } 4.2 Model 1 From the “Starting off” section, we see that health factors and type can be useful factors in predicting adoption speed. 4.2.1 Model Building \\[\\text{For Bayesian Ordinal Regression, we introduce a latent variable }y^*,\\text{ modeled as a linear function with our chosen predictors,} \\\\\\text{ the vector }\\zeta\\text{ with 4 cutpoints, and let }Y_i\\text{ be the ordinal outcome for the ith animal with 5 possible adoption speeds.}\\] \\[\\\\Y_i|\\zeta_1,...,\\zeta_4,\\beta_1,...,\\beta_6 = \\left\\{ \\begin{array}{ll} 0 &amp; \\quad y^* &lt; \\zeta_1 \\\\ 1 &amp; \\quad \\zeta_1 \\leq y^* &lt; \\zeta_2 \\\\ 2 &amp; \\quad \\zeta_2 \\leq y^* &lt; \\zeta_3 \\\\ 3 &amp; \\quad \\zeta_3 \\leq y^* &lt; \\zeta_4\\\\ 4 &amp; \\quad y^*\\ge \\zeta_4 \\end{array} \\right.\\] \\[y^*=\\beta_1x_1+\\beta_2x_2+...+\\beta_6x_6\\]where \\(x_n\\) for n from 1 to 6 are the indicators for cat, minor injury, severe injury, sterilization, vaccination, and dewormed. And \\(\\beta_n\\) are the coefficients for these indicators. \\[\\zeta_1 \\sim N(m_{01},s_{01}^2) \\\\... \\\\\\beta_1 \\sim N(m_1,s_1^2) \\\\...\\] For this model, we will be setting a R2 prior, which is the proportion of variance in the outcome that is attributable to the coefficients in our linear model. Since we don’t have any prior information, we will set a standard uniform prior on R2. model1 &lt;- stan_polr(AdoptionSpeed ~ Type+Health+Sterilized+Vaccinated+Dewormed, data =mysample, prior=R2(0.5,what=NULL),iter=5000, seed = 454) 4.2.2 Posterior Inference model1_summary&lt;-summary(model1) head(as.data.frame(model1_summary), -2) ## mean mcse sd 10% 50% ## Type1 -0.291472332 1.067107e-03 0.128917172 -0.45490997 -0.291619825 ## Health1 0.441523473 3.135560e-03 0.350471059 -0.01079189 0.437815394 ## Health2 2.289862443 1.401822e-02 1.356098798 0.68125324 2.195511682 ## Sterilized1 0.690688772 1.535365e-03 0.164162835 0.48092258 0.688819102 ## Vaccinated1 0.318715747 1.655190e-03 0.179963272 0.08924947 0.318538724 ## Dewormed1 -0.001789522 1.616438e-03 0.168594313 -0.21720001 -0.001004759 ## 0|1 -3.355148548 2.201978e-03 0.232536209 -3.65773490 -3.349498499 ## 1|2 -1.058289904 1.284121e-03 0.139953255 -1.23837624 -1.057180267 ## 2|3 0.276656461 1.187258e-03 0.133952418 0.10538132 0.276139337 ## 3|4 1.272267361 1.207162e-03 0.140589158 1.09125504 1.271952833 ## mean_PPD:0 0.031505172 8.265987e-05 0.008632395 0.02093596 0.030788177 ## mean_PPD:1 0.203957020 1.955397e-04 0.019572049 0.17980296 0.203201970 ## mean_PPD:2 0.288257266 2.204405e-04 0.022416216 0.25985222 0.288177340 ## mean_PPD:3 0.214343966 1.973403e-04 0.020048851 0.18965517 0.214285714 ## 90% n_eff Rhat ## Type1 -0.12640415 14595 0.9999596 ## Health1 0.89662335 12493 0.9997813 ## Health2 4.02976553 9358 0.9999248 ## Sterilized1 0.90384820 11432 1.0000488 ## Vaccinated1 0.54993335 11821 0.9998534 ## Dewormed1 0.21453193 10878 0.9998297 ## 0|1 -3.06134550 11152 1.0000541 ## 1|2 -0.87929294 11878 0.9998446 ## 2|3 0.44947033 12729 1.0000083 ## 3|4 1.45397384 13564 1.0001160 ## mean_PPD:0 0.04310345 10906 0.9999094 ## mean_PPD:1 0.23029557 10018 0.9999413 ## mean_PPD:2 0.31650246 10341 1.0001028 ## mean_PPD:3 0.24014778 10322 1.0000672 set.seed(454) model_data1&lt;-mysample %&gt;% dplyr::select(AdoptionSpeed, Type,Health,Sterilized,Vaccinated,Dewormed) %&gt;% na.omit() my_prediction1 &lt;- posterior_predict( model1, newdata = model_data1) ordinal_accuracy(my_prediction1,model_data1) ## [1] 0.2438424 The formula using the posterior means of each variable is: \\[y^*=-0.291*Type+0.442*Health1+2.290*Health2+0.691*Sterilized1 \\\\+0.319*Vaccinated1-0.002*Dewormed1 \\\\{\\zeta_1,...\\zeta_4}={0,-3.62,-1.42,-0.17,0.76}\\text{ respectively}\\] The accuracy for this model is 0.244. If an animal is a cat, then \\(y^*\\) will decrease by 0.291, making the animal more likely to get adopted faster than a dog, keeping all other variables constant. We can see that the mean of Dewormed is near zero, therefore, we will exclude Dewormed in our future model. 4.3 Model 2 With further investigations, we have also found “AgeGroup” and “mix_breed” to be important factors (visualizations from the “More digging” section). We will include these in our models. 4.3.1 Model Building \\[\\text{Let }y^*\\text{ be the latent variable, }\\zeta\\text{ be the vector with 4 cutpoints, and }Y_i\\text{ be the } \\\\\\text{ ordinal outcome for the ith animal with 5 possible adoption speeds.}\\] \\[\\\\Y_i|\\zeta_1,...,\\zeta_4,\\beta_1,...,\\beta_{10} = \\left\\{ \\begin{array}{ll} 0 &amp; \\quad y^* &lt; \\zeta_1 \\\\ 1 &amp; \\quad \\zeta_1 \\leq y^* &lt; \\zeta_2 \\\\ 2 &amp; \\quad \\zeta_2 \\leq y^* &lt; \\zeta_3 \\\\ 3 &amp; \\quad \\zeta_3 \\leq y^* &lt; \\zeta_4\\\\ 4 &amp; \\quad y^*\\ge \\zeta_4 \\end{array} \\right.\\] \\[y^*=\\beta_1x_1+\\beta_2x_2+...+\\beta_{11}x_{11}\\] where \\(x_n\\) for n from 1 to 11 are the indicators for cat, minor/severe injury, sterilization, vaccination, age groups 1-5, and Mix breed. \\[\\zeta_1 \\sim N(m_{01},s_{01}^2) \\\\... \\\\\\beta_1 \\sim N(m_1,s_1^2) \\\\...\\] model2 &lt;- stan_polr(AdoptionSpeed ~ Type+Health+Sterilized+Vaccinated+AgeGroup+MixedBreed, data =mysample, prior=R2(0.5,what=NULL),iter=5000, seed = 454) 4.3.2 Posterior Inference model2_summary&lt;- summary(model2) head(as.data.frame(model2_summary), -2) ## mean mcse sd 10% 50% ## Type1 0.48778366 1.707863e-03 0.221427458 0.19976369 0.48937164 ## Health1 0.47969467 3.195916e-03 0.348317802 0.03818016 0.47965636 ## Health2 1.67486939 1.220502e-02 1.279389983 0.13553622 1.58676636 ## Sterilized1 0.47813952 1.457010e-03 0.181320803 0.24420605 0.47770227 ## Vaccinated1 0.24826375 1.199002e-03 0.149064908 0.05697017 0.24762385 ## AgeGroup1 0.54348134 1.459234e-03 0.170443602 0.32467603 0.54231742 ## AgeGroup2 0.66716931 1.993412e-03 0.227959035 0.37680824 0.66989071 ## AgeGroup3 0.96625893 3.180660e-03 0.345682844 0.51766283 0.95983629 ## AgeGroup4 0.65239525 3.793133e-03 0.437359847 0.08932112 0.64813984 ## AgeGroup5 0.53430605 5.266733e-03 0.592109782 -0.22336947 0.52774019 ## MixedBreed1 1.06601710 2.044574e-03 0.228975968 0.77289049 1.06582076 ## 0|1 -2.45032288 2.856396e-03 0.287372279 -2.81857404 -2.44775572 ## 1|2 -0.13451482 2.159830e-03 0.230288981 -0.43149332 -0.13648189 ## 2|3 1.23866701 2.011140e-03 0.232081787 0.93921284 1.23811248 ## 3|4 2.26420168 2.033693e-03 0.241510274 1.95486028 2.26515793 ## mean_PPD:0 0.03138345 7.841415e-05 0.008449069 0.02068127 0.03041363 ## mean_PPD:1 0.20154197 1.840315e-04 0.019143089 0.17761557 0.20072993 ## mean_PPD:2 0.28724696 2.128690e-04 0.022075926 0.25912409 0.28710462 ## mean_PPD:3 0.21470985 1.891734e-04 0.019819265 0.18978102 0.21411192 ## 90% n_eff Rhat ## Type1 0.76985933 16810 0.9998001 ## Health1 0.92512579 11878 0.9998389 ## Health2 3.31114337 10988 0.9999712 ## Sterilized1 0.70659244 15487 0.9997555 ## Vaccinated1 0.43924717 15457 0.9997827 ## AgeGroup1 0.76354356 13643 1.0000624 ## AgeGroup2 0.95776625 13077 0.9998310 ## AgeGroup3 1.41472859 11812 0.9996562 ## AgeGroup4 1.21477049 13295 0.9997109 ## AgeGroup5 1.29127895 12639 0.9998504 ## MixedBreed1 1.35920999 12542 0.9997835 ## 0|1 -2.08201004 10122 0.9998176 ## 1|2 0.16165719 11369 0.9997512 ## 2|3 1.53309341 13317 0.9998544 ## 3|4 2.57697695 14103 0.9998261 ## mean_PPD:0 0.04257908 11610 0.9998802 ## mean_PPD:1 0.22627737 10820 1.0000967 ## mean_PPD:2 0.31630170 10755 0.9999731 ## mean_PPD:3 0.23965937 10976 0.9998674 set.seed(454) model_data2&lt;-mysample %&gt;% dplyr::select(AdoptionSpeed, Type,Health,Sterilized,Vaccinated,AgeGroup,MixedBreed) %&gt;% na.omit() my_prediction2 &lt;- posterior_predict( model2, newdata = model_data2) ordinal_accuracy(my_prediction2,model_data2) ## [1] 0.2372263 The model accuracy is 0.24. If an animal has a severe injury, then \\(y^*\\) will increase by 2.290, making it more likely to get adopted slower than a healthy animal, keeping all other variables constant. We can see that the mean of Dewormed is near zero, therefore, we will exclude Dewormed in our future model. If an animal is in age group 1(4 to 11 months), then \\(y^*\\) will increase by 0.5, making the animal more likely to get adopted slower than an animal in age group 0, keeping all other variables constant. Similar situations apply to other age groups as well. From this, we can reasonably infer that animals in age group 0 are the most popular. If an animal is a Mixed Breed, then \\(y^*\\) will increase by 1.1, making them more likely to get adopted slower than an animal that is not mixed breed, keeping all other variables constant. 4.4 Making some adjustments Our accuracy is less than ideal. One reason behind this could be due to how adoption speed is grouped. Group 0 is being adopted the day of, group 1 is being adopted between 2-7 days, and group 2 is being adopted between 8-30 days. The difference between group 0,1, and 2 can be due to chance. Therefore, I’ve decided to group groups 0,1, and 2 into 1 group. In our future models, we will be predicting for 3 adoption speed groups. 4.5 Model 3 In this model, we will be adding two interaction terms. The figure below shows that the younger the animal is, the less likely it will get sterilized, since the procedure can’t be done when they are young. I have also realized that only dogs can be marked as mixed breed. Therefore, we will add two interaction terms: Type\\(*\\)MixedBreed and AgeGroup\\(*\\)Sterilization. set.seed(454) mysample2 &lt;- adoption[sample(1:nrow(adoption), 1000, replace=FALSE),] ordinal_accuracy2&lt;-function(post_preds,mydata){ post_preds&lt;-as.data.frame(post_preds) results&lt;-c() for (j in (1:length(post_preds))){ results[j]&lt;-as.numeric(tail(names(sort(table(post_preds[,j]))))[3]) } results&lt;-as.data.frame(results) compare&lt;-cbind(results,mydata$AdoptionSpeed_Group) compare&lt;-compare %&gt;%mutate(results=as.numeric(results)) compare&lt;-compare %&gt;% mutate(`mydata$AdoptionSpeed_Group`=as.numeric(`mydata$AdoptionSpeed_Group`)) compare&lt;-compare %&gt;%mutate(accuracy=ifelse(as.numeric(results)==as.numeric(`mydata$AdoptionSpeed_Group`),1,0)) print(sum(compare$accuracy)/length(post_preds)) } 4.5.1 Model Building \\[\\text{Let }y^*\\text{ be the latent variable, }\\zeta\\text{ be the vector with 2 cutpoints, and }Y_i\\text{ be the } \\\\\\text{ ordinal outcome for the ith animal with 3 possible adoption speeds.}\\] \\[Y_i|\\zeta_1,\\zeta_2,\\beta_1,...,\\beta_{17} = \\left\\{ \\begin{array}{ll} 1 &amp; \\quad y^* &lt; \\zeta_1 \\\\ 2 &amp; \\quad \\zeta_1 \\leq y^* &lt; \\zeta_2 \\\\ 3 &amp; \\quad \\zeta_2 \\leq y^* \\end{array} \\right.\\] \\[ y^*=\\beta_1x_1...+\\beta_{10}x_{10}+\\beta_{11}x_1*x_10+\\beta_{12}x_2*x_5+...+\\beta_{17}x_2*x_9\\] where \\(x_n\\) for n from 1 to 11 is the indicator for cat, minor/severe injury, sterilization, vaccination, age groups 1-5, and Mix breed.\\(\\beta_{12}\\) is the coefficient for the interaction term of \\(Type*MixedBreed\\), and \\(\\beta_{13}\\) to \\(\\beta_{17}\\) are the coefficients for the interaction terms of \\(AgeGroup*Sterilization\\). \\[\\\\\\zeta_1 \\sim N(m_{01},s_{01}^2) \\\\... \\\\\\beta_1 \\sim N(m_1,s_1^2) \\\\...\\] model3 &lt;- stan_polr(AdoptionSpeed_Group ~ Type+MixedBreed+Health+Vaccinated+AgeGroup+Sterilized, data=mysample2, prior=R2(0.5,what= NULL),iter=5000, seed = 454) 4.5.2 Posterior Inference model3_summary&lt;- summary(model3) head(as.data.frame(model3_summary), -2) ## mean mcse sd 10% 50% 90% ## Type1 0.3451827 0.0019710823 0.23476422 0.04353292 0.3425949 0.6421678 ## MixedBreed1 0.9758830 0.0022277932 0.24084355 0.66773156 0.9752728 1.2843762 ## Health1 0.5549085 0.0031939476 0.35711011 0.09364087 0.5573441 1.0099537 ## Health2 1.6569184 0.0128234459 1.29691140 0.12056026 1.5538236 3.3182407 ## Vaccinated1 0.1700844 0.0012275795 0.16079859 -0.03401840 0.1706597 0.3776179 ## AgeGroup1 0.5505604 0.0016178448 0.18017912 0.31706524 0.5493472 0.7840974 ## AgeGroup2 0.7259747 0.0019790205 0.23643728 0.42795142 0.7253973 1.0323629 ## AgeGroup3 0.9113914 0.0030942282 0.35135824 0.46744848 0.9097726 1.3594050 ## AgeGroup4 0.5862925 0.0040405589 0.47104174 -0.01181623 0.5814861 1.1957654 ## AgeGroup5 0.3243656 0.0055521388 0.64586317 -0.51509322 0.3412998 1.1392635 ## Sterilized1 0.5207101 0.0016653392 0.18600371 0.28016222 0.5200531 0.7599464 ## 1|2 1.1190016 0.0022699191 0.24307702 0.80645532 1.1160157 1.4277635 ## 2|3 2.1449649 0.0022639660 0.25308847 1.82145025 2.1405737 2.4761848 ## mean_PPD:1 0.5203933 0.0002372490 0.02376417 0.49026764 0.5206813 0.5510949 ## mean_PPD:2 0.2144968 0.0002032269 0.02032452 0.18856448 0.2141119 0.2408759 ## n_eff Rhat ## Type1 14186 0.9997899 ## MixedBreed1 11687 0.9999682 ## Health1 12501 1.0000555 ## Health2 10228 1.0002430 ## Vaccinated1 17158 0.9996834 ## AgeGroup1 12403 1.0002466 ## AgeGroup2 14274 0.9998599 ## AgeGroup3 12894 0.9997617 ## AgeGroup4 13591 0.9999414 ## AgeGroup5 13532 0.9999226 ## Sterilized1 12475 1.0003604 ## 1|2 11467 0.9998890 ## 2|3 12497 0.9998815 ## mean_PPD:1 10033 1.0001560 ## mean_PPD:2 10002 0.9998024 set.seed(454) model_data3&lt;-mysample2 %&gt;% dplyr::select(AdoptionSpeed_Group, Type,Health,Sterilized,Vaccinated,AgeGroup,MixedBreed) %&gt;% na.omit() my_prediction3 &lt;- posterior_predict( model3, newdata = model_data3) ordinal_accuracy2(my_prediction3,model_data3) ## [1] 0.5596107 The model accuracy is 0.560, that’s a big improvement! From the model summary, we notice that 0 is about one standard deviation away from the mean of vaccination’s coefficient. Therefore, we will exclude vaccination in our final model. "],
["final-model.html", "Chapter 5 Final Model 5.1 Model Building 5.2 Diagnostic Plots 5.3 Posterior Inference 5.4 Discussion", " Chapter 5 Final Model Finally! We are ready for our final model! Now, let’s use our test and train data. load(&#39;adoption.RData&#39;) set.seed(454) adoption_split &lt;- initial_split(adoption, prop = .7) adoption_train &lt;- training(adoption_split) adoption_test &lt;- testing(adoption_split) 5.1 Model Building \\[\\text{Let }y^*\\text{ be the latent variable, }\\zeta\\text{ be the vector with 2 cutpoints, and }Y_i\\text{ be the } \\\\\\text{ ordinal outcome for the ith animal with 3 possible adoption speeds.}\\] \\[Y_i|\\zeta_1,\\zeta_2,\\beta_1,...,\\beta_{16} = \\left\\{ \\begin{array}{ll} 1 &amp; \\quad y^* &lt; \\zeta_1 \\\\ 2 &amp; \\quad \\zeta_1 \\leq y^* &lt; \\zeta_2 \\\\ 3 &amp; \\quad \\zeta_2 \\leq y^* \\end{array} \\right.\\] \\[y^*=\\beta_1x_1...+\\beta_{10}x_{10}+\\beta_{11}x_1*x_10+\\beta_{12}x_2*x_5+...+\\beta_{16}x_2*x_9\\] where \\(x_n\\) for n from 1 to 10 is the indicator for cat, minor/severe injury, sterilization, age groups 1-5, and Mix breed.\\(\\beta_{11}\\) is the coefficient for the interaction term of \\(Type*MixedBreed\\), and \\(\\beta_{12}\\) to \\(\\beta_{16}\\) are the coefficients for the interaction terms of \\(AgeGroup*Sterilization\\). \\[\\\\\\zeta_1 \\sim N(m_{01},s_{01}^2) \\\\... \\\\\\beta_1 \\sim N(m_1,s_1^2) \\\\...\\] final_model &lt;- stan_polr(AdoptionSpeed_Group ~ Type*MixedBreed+Health+Sterilized*AgeGroup, data =adoption_train, prior=R2(0.5,what=NULL),iter=5000, seed = 454) 5.2 Diagnostic Plots Let’s look at some diagnostic plots! All of these plots don’t show any abnormal pattern and the chains overlap with each other. mcmc_trace(final_model) mcmc_dens_overlay(final_model) pp_check(final_model) 5.3 Posterior Inference final_model_summary&lt;- summary(final_model) head(as.data.frame(final_model_summary), -2) ## mean mcse sd 10% ## Type1 0.55324562 5.450454e-04 0.067972248 0.46483044 ## MixedBreed1 1.06318355 6.057704e-04 0.069597623 0.97480407 ## Health1 0.21518841 1.110681e-03 0.122186905 0.06095336 ## Health2 0.46906848 4.657286e-03 0.485278981 -0.15002129 ## Sterilized1 0.70538087 1.342419e-03 0.140259684 0.52140574 ## AgeGroup1 0.88612023 5.265084e-04 0.059696574 0.80957865 ## AgeGroup2 1.07574108 8.196934e-04 0.087154667 0.96498714 ## AgeGroup3 0.97119919 1.484276e-03 0.160364847 0.76596417 ## AgeGroup4 0.69497692 2.420120e-03 0.245471775 0.38302011 ## AgeGroup5 1.23313469 2.739425e-03 0.301253163 0.84356176 ## Type1:MixedBreed1 16.38712159 2.788769e-01 12.224207824 3.10183396 ## Sterilized1:AgeGroup1 -0.34854266 1.592412e-03 0.166436814 -0.56054245 ## Sterilized1:AgeGroup2 -0.24287677 1.695753e-03 0.174026062 -0.46464188 ## Sterilized1:AgeGroup3 -0.36499681 2.226908e-03 0.231066947 -0.65942334 ## Sterilized1:AgeGroup4 -0.08299334 3.264202e-03 0.321884568 -0.49697579 ## Sterilized1:AgeGroup5 -0.32553321 3.801849e-03 0.381588876 -0.81327658 ## 1|2 1.26453439 5.979261e-04 0.068066142 1.17738499 ## 2|3 2.32111604 6.076589e-04 0.071312780 2.22969547 ## mean_PPD:1 0.51028151 7.234882e-05 0.007008311 0.50135325 ## mean_PPD:2 0.22274171 5.927455e-05 0.006181765 0.21489661 ## 50% 90% n_eff Rhat ## Type1 0.5533768 0.64007248 15552 0.9996826 ## MixedBreed1 1.0631939 1.15079427 13200 0.9997197 ## Health1 0.2147546 0.36975078 12102 0.9999215 ## Health2 0.4669237 1.08419208 10857 0.9998238 ## Sterilized1 0.7071647 0.88462549 10917 1.0003414 ## AgeGroup1 0.8856529 0.96257346 12855 0.9997073 ## AgeGroup2 1.0755650 1.18602234 11305 0.9997492 ## AgeGroup3 0.9709156 1.17491749 11673 0.9997387 ## AgeGroup4 0.6991856 1.00797587 10288 0.9999504 ## AgeGroup5 1.2372309 1.61889575 12093 0.9997890 ## Type1:MixedBreed1 13.8552125 33.40589650 1921 1.0013566 ## Sterilized1:AgeGroup1 -0.3501312 -0.13333359 10924 0.9999779 ## Sterilized1:AgeGroup2 -0.2457145 -0.02067051 10532 1.0000624 ## Sterilized1:AgeGroup3 -0.3655172 -0.06871630 10766 0.9999318 ## Sterilized1:AgeGroup4 -0.0837725 0.32655525 9724 0.9998016 ## Sterilized1:AgeGroup5 -0.3358608 0.17423792 10074 0.9998414 ## 1|2 1.2637562 1.35222578 12959 0.9997043 ## 2|3 2.3203994 2.41246188 13773 0.9996658 ## mean_PPD:1 0.5103389 0.51921620 9383 0.9998999 ## mean_PPD:2 0.2227996 0.23048609 10876 1.0001687 set.seed(454) model_data&lt;-adoption_test %&gt;% dplyr::select(AdoptionSpeed_Group,Type,Health,AgeGroup,MixedBreed,Sterilized) %&gt;% na.omit() final_prediction &lt;- posterior_predict( final_model, newdata = model_data) ordinal_accuracy2(final_prediction,model_data) ## [1] 0.5531591 ordinal_predictions&lt;-function(post_preds,mydata){ post_preds&lt;-as.data.frame(post_preds) results&lt;-c() for (j in (1:length(post_preds))){ results[j]&lt;-as.numeric(tail(names(sort(table(post_preds[,j]))))[3]) } results&lt;-as.data.frame(results) compare&lt;-cbind(results,mydata$AdoptionSpeed_Group) compare&lt;-compare %&gt;%mutate(results=as.numeric(results)) compare&lt;-compare %&gt;% mutate(`mydata$AdoptionSpeed_Group`=as.numeric(`mydata$AdoptionSpeed_Group`)) compare&lt;-compare %&gt;%mutate(accuracy=ifelse(as.numeric(results)==as.numeric(`mydata$AdoptionSpeed_Group`),1,0)) compare&lt;-compare %&gt;% mutate(pred=ifelse(accuracy==1,as.numeric(`mydata$AdoptionSpeed_Group`),0)) compare %&gt;% count(pred) } ordinal_predictions(final_prediction,model_data) ## # A tibble: 3 x 2 ## pred n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 1761 ## 2 1 1791 ## 3 3 389 model_data %&gt;% count(AdoptionSpeed_Group) ## # A tibble: 3 x 2 ## AdoptionSpeed_Group n ## &lt;fct&gt; &lt;int&gt; ## 1 1 2017 ## 2 2 923 ## 3 3 1001 Our final accuracy is 55.3%. We can see that our model successfully predicts most of the animals in “Adoption Speed 1”, about 1/3 of the animals in “Adoption Speed 3”, and did not predict any for “Adoption Speed 2”. This could be partially attributable to the fact that we have more animals in group 1. While the expected value of the cofficient for \\(Type*MixedBreed\\) is 16.4, the standard deviation is fairly large, demonstrating that the variable might be not as significant. The expected value of the cofficient for \\(sterilized*AgeGroup\\) are more significant for animals in agegroup 1 and 2. If an animal is in age group1 and sterilized, then \\(y^*\\) will decrease by 0.35, making it more likely to get adopted faster than an animal that is not sterilized and not in age group 1, keeping all other variables constant. 5.4 Discussion Our model demonstrates that an animal’s health status, sterilization records, age, type (dog/cat), and whether it’s a mixed breed dog or are the factors that are most indicative of the animal’s adoption speed. Our model doesn’t have the most ideal accuracy, and I think this could be attributable to the fact that pet adoption is a rather personal process that varies for each person and animal. For future models, it would be helpful to see if we can downsample when modeling, this might raise the accuracy for “Adoption Speed 2”. One variable that I think can help improve this model is a score of the animal’s appearance. The cuteness/attractiveness of the animal probably plays an important role in the animal adoption process. I noticed that “Mixed Breed” dogs are more likely to get adopted slower, and I this might be due to the fact that theyir appearance are less cute/attractive than pure breed dogs. "],
["shiny-apps.html", "Chapter 6 Shiny Apps! 6.1 User Input", " Chapter 6 Shiny Apps! 6.1 User Input User Input in the Shiny App Description Age Group 0: 0-3 months; 1: 4-11 months; 2: 12-30 months; 3: 31-59 months; 4: 60-82 months; 5: 83 months or older Health 0: healthy; 1: minor injury; 2: severe injury Sterilization 0: not sterilized; 1: sterilized Mixed Breed 0: not mixed-breed; 1: mix-breed Type 0: dog, 1: cat Here’s the shiny app: https://cornerz.shinyapps.io/pet-adoption-shiny/ Enjoy! "],
["final-reflections.html", "Chapter 7 Final Reflections 7.1 Advice for first time capstone people 7.2 Acknowledgements 7.3 Citations", " Chapter 7 Final Reflections 7.1 Advice for first time capstone people 7.1.1 Individual work Take some time to choose the data: having good data will make it so much easier for you to come up with a plausible research question and choose an appropriate model. Have a plan and stay on top of it: the way I usually do it is to create a checklist everyday for things I want to accomplish for the project. This keeps me motivated and on track for the project. It’s even better to come up with a general outline in the beginning and start filling each item on the outline with more specific to-dos. Ask for help: you should definitely try to figure things out by yourself first, but if you feel stuck, ask for help! Your group members and proffessor are there for you :) Be confident and persevere: I can’t even count the number of times I wanted to give up as I was doing this project. I started doubting my abilities, blaming myself for not being smarter, and eventually trying to convince myself to do a simpler version of the project. But then I look back at all the work I have already done for the project, and I know that I have learned a semester of Bayesian statistics, so I must have what it takes to complete the project. Be confident in your abilities and persevere! Take care of yourself! I feel like this is the most important advice anyone can give to another person. If you are not in a healthy state both physically and mentally, you won’t be able to do the work well. I find that taking a walk with my dog, eatting good food, and keeping myself hydrated is super helpful. My “guilty pleasure” for rewinding after a day of hard work is to watch really cheesy movies or tv shows, like the “twilight” saga and “pretty little liars”. 7.1.2 Group work Know how your group members work and adjust your expectations accordingly: for example, if your group members are people who turn things in on the day it’s due, then don’t stress if you think they are working too slow :) Be prepared to take on more responsibilities: I know that we often try to divide the work as equally as possible when it comes to group projects, but things often don’t work out the way we expect it to. It could be because one of your group member is slacking off or new tasks came up for the project. Just be mentally prepared that you would probably do more work than you were planning to do. Communicate: I think this is the most important rule for group work; make sure you and your group members are on the same page regarding how to split the work and expectations for the project. 7.2 Acknowledgements I want to thank Dr. Alicia Johnson for teaching me everything I know about Bayesian Statistics, offering me a ton of useful feedbacks, and helping me through all the challenges I have encountered for this project. I also want to thank Dr. Brianna Heggeseth for introducing me to the beauty of statistics, teaching me how to clean data, and helping me understand ordinal logistic regression. Finally, I want to thank Esther Swehla and Christina Cai for reading my work and giving me some good ideas about the project. 7.3 Citations “PetFinder.my Adoption Prediction.” Kaggle. Accessed April 19, 2020. https://www.kaggle.com/c/petfinder-adoption-prediction/data. “PetFinder.my Adoption Prediction Discussion 86581.” Kaggle. Accessed April 19, 2020. https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/86581 Gabry, Jonah, and Ben Goodrich. Estimating Ordinal Regression Models with rstanarm, February 11, 2020. https://cran.r-project.org/web/packages/rstanarm/vignettes/polr.html. Gabry, Jonah, and Ben Goodrich. Estimating Regularized Linear Models with rstanarm, February 11, 2020. https://cran.r-project.org/web/packages/rstanarm/vignettes/lm.html. UCLA. “ORDINAL LOGISTIC REGRESSION | R DATA ANALYSIS EXAMPLES.” IDRE Stats. Accessed April 19, 2020. https://stats.idre.ucla.edu/r/dae/ordinal-logistic-regression/. "]
]
